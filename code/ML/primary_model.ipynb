{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee94d91e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444b5220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462f80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix,\\\n",
    "                             explained_variance_score, mean_squared_error, max_error, mean_absolute_error,\\\n",
    "                             root_mean_squared_error, median_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "# pas besoin de feature selection parce que pas beacoup de colonnes\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc0980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_mist_models\n",
    "\n",
    "from utils import Iso_data_handler\n",
    "\n",
    "def gaussian(dsts):\n",
    "    kernel_width = .5\n",
    "    weights = np.exp(-(dsts**2)/kernel_width)\n",
    "    return weights\n",
    "\n",
    "# To find certain rows\n",
    "\n",
    "def isclose_pandas_apply(row, col_name, value, bool_index, rel_tol=1e-6):\n",
    "    if math.isclose(row[col_name], value, rel_tol=rel_tol):\n",
    "        bool_index.append(True)\n",
    "    else:\n",
    "        bool_index.append(False)\n",
    "\n",
    "def isclose_pandas(df, col_name, value, rel_tol=1e-6):\n",
    "    bool_index = []\n",
    "    df.apply(isclose_pandas_apply, axis=1, args=(col_name, value, bool_index, rel_tol))\n",
    "    return bool_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a5ebdc",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59cb528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_handler = Iso_data_handler(\"C:/Users/antoi/Code/unif/MA2/Thèse/data/MIST_v1.2_vvcrit0.0_basic_isos/\", \n",
    "                              ['log10_isochrone_age_yr', 'log_Teff', 'log_g', 'star_mass', 'phase', 'metallicity', 'log_R'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d79452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataframe from csv file...\n"
     ]
    }
   ],
   "source": [
    "iso_df = iso_handler.full_iso_data_to_panda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c0bc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_isochrone_age_yr</th>\n",
       "      <th>log_Teff</th>\n",
       "      <th>log_g</th>\n",
       "      <th>star_mass</th>\n",
       "      <th>phase</th>\n",
       "      <th>metallicity</th>\n",
       "      <th>log_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.486221</td>\n",
       "      <td>3.131342</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.153402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.487362</td>\n",
       "      <td>3.126808</td>\n",
       "      <td>0.102645</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.160326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.489243</td>\n",
       "      <td>3.119367</td>\n",
       "      <td>0.107039</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.171785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.491102</td>\n",
       "      <td>3.112165</td>\n",
       "      <td>0.111419</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.183099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.492937</td>\n",
       "      <td>3.105143</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.194305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467117</th>\n",
       "      <td>10.3</td>\n",
       "      <td>4.402490</td>\n",
       "      <td>7.777159</td>\n",
       "      <td>0.532726</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.806255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467118</th>\n",
       "      <td>10.3</td>\n",
       "      <td>4.387132</td>\n",
       "      <td>7.783242</td>\n",
       "      <td>0.532730</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.809295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467119</th>\n",
       "      <td>10.3</td>\n",
       "      <td>4.371789</td>\n",
       "      <td>7.789130</td>\n",
       "      <td>0.532735</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.812237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467120</th>\n",
       "      <td>10.3</td>\n",
       "      <td>4.356480</td>\n",
       "      <td>7.794844</td>\n",
       "      <td>0.532741</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.815091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467121</th>\n",
       "      <td>10.3</td>\n",
       "      <td>4.341226</td>\n",
       "      <td>7.800376</td>\n",
       "      <td>0.532749</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-1.817854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1467122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         log10_isochrone_age_yr  log_Teff     log_g  star_mass  phase  \\\n",
       "0                           5.0  3.486221  3.131342   0.100000   -1.0   \n",
       "1                           5.0  3.487362  3.126808   0.102645   -1.0   \n",
       "2                           5.0  3.489243  3.119367   0.107039   -1.0   \n",
       "3                           5.0  3.491102  3.112165   0.111419   -1.0   \n",
       "4                           5.0  3.492937  3.105143   0.115789   -1.0   \n",
       "...                         ...       ...       ...        ...    ...   \n",
       "1467117                    10.3  4.402490  7.777159   0.532726    6.0   \n",
       "1467118                    10.3  4.387132  7.783242   0.532730    6.0   \n",
       "1467119                    10.3  4.371789  7.789130   0.532735    6.0   \n",
       "1467120                    10.3  4.356480  7.794844   0.532741    6.0   \n",
       "1467121                    10.3  4.341226  7.800376   0.532749    6.0   \n",
       "\n",
       "         metallicity     log_R  \n",
       "0              -0.25  0.153402  \n",
       "1              -0.25  0.160326  \n",
       "2              -0.25  0.171785  \n",
       "3              -0.25  0.183099  \n",
       "4              -0.25  0.194305  \n",
       "...              ...       ...  \n",
       "1467117         0.50 -1.806255  \n",
       "1467118         0.50 -1.809295  \n",
       "1467119         0.50 -1.812237  \n",
       "1467120         0.50 -1.815091  \n",
       "1467121         0.50 -1.817854  \n",
       "\n",
       "[1467122 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(iso_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f22948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only the relevant star phases\n",
    "phase_filtered_iso_df = iso_df\\\n",
    "    .where((iso_df.phase == 0) | (iso_df.phase == 2) | (iso_df.phase == 3) | (iso_df.phase == 4) | (iso_df.phase == 5))\\\n",
    "    .dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3564b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_isochrone_age_yr</th>\n",
       "      <th>log_Teff</th>\n",
       "      <th>log_g</th>\n",
       "      <th>star_mass</th>\n",
       "      <th>phase</th>\n",
       "      <th>metallicity</th>\n",
       "      <th>log_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.494412</td>\n",
       "      <td>4.346972</td>\n",
       "      <td>13.584360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.610679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.497517</td>\n",
       "      <td>4.345776</td>\n",
       "      <td>13.765512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.614753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.500556</td>\n",
       "      <td>4.344580</td>\n",
       "      <td>13.942887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.618755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.504040</td>\n",
       "      <td>4.343050</td>\n",
       "      <td>14.591712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.624670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.507576</td>\n",
       "      <td>4.341483</td>\n",
       "      <td>15.426062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.631187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165292</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.425746</td>\n",
       "      <td>-0.551440</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.384899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165293</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.426469</td>\n",
       "      <td>-0.560350</td>\n",
       "      <td>0.598549</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.387797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165294</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.427744</td>\n",
       "      <td>-0.566057</td>\n",
       "      <td>0.594116</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.389036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165295</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.429413</td>\n",
       "      <td>-0.569225</td>\n",
       "      <td>0.589648</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.388981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165296</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.431389</td>\n",
       "      <td>-0.569398</td>\n",
       "      <td>0.585631</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.387582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1165297 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         log10_isochrone_age_yr  log_Teff     log_g  star_mass  phase  \\\n",
       "0                           5.0  4.494412  4.346972  13.584360    0.0   \n",
       "1                           5.0  4.497517  4.345776  13.765512    0.0   \n",
       "2                           5.0  4.500556  4.344580  13.942887    0.0   \n",
       "3                           5.0  4.504040  4.343050  14.591712    0.0   \n",
       "4                           5.0  4.507576  4.341483  15.426062    0.0   \n",
       "...                         ...       ...       ...        ...    ...   \n",
       "1165292                    10.3  3.425746 -0.551440   0.602856    5.0   \n",
       "1165293                    10.3  3.426469 -0.560350   0.598549    5.0   \n",
       "1165294                    10.3  3.427744 -0.566057   0.594116    5.0   \n",
       "1165295                    10.3  3.429413 -0.569225   0.589648    5.0   \n",
       "1165296                    10.3  3.431389 -0.569398   0.585631    5.0   \n",
       "\n",
       "         metallicity     log_R  \n",
       "0              -0.25  0.610679  \n",
       "1              -0.25  0.614753  \n",
       "2              -0.25  0.618755  \n",
       "3              -0.25  0.624670  \n",
       "4              -0.25  0.631187  \n",
       "...              ...       ...  \n",
       "1165292         0.50  2.384899  \n",
       "1165293         0.50  2.387797  \n",
       "1165294         0.50  2.389036  \n",
       "1165295         0.50  2.388981  \n",
       "1165296         0.50  2.387582  \n",
       "\n",
       "[1165297 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(phase_filtered_iso_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c98cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(873972, 4) (291325, 4)\n",
      "(873972, 2) (291325, 2)\n"
     ]
    }
   ],
   "source": [
    "X = phase_filtered_iso_df.drop(['star_mass', 'phase', 'log_R'], axis=1).to_numpy()\n",
    "y = phase_filtered_iso_df[['star_mass', 'log_R']].to_numpy()\n",
    "\n",
    "X_TRAIN, X_IVS, y_TRAIN, y_IVS = train_test_split(X, y, test_size=0.25, random_state=1337)\n",
    "\n",
    "print(X_TRAIN.shape, X_IVS.shape)\n",
    "print(y_TRAIN.shape, y_IVS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b4c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range in train data for the mass parameter : 0.0999979840073621 - 296.5221171165397\n",
      "Median value in train data for the mass parameter: 2.0298876569807147\n",
      "Mean value in train data for the mass parameter: 7.387582424532589\n",
      "Range in test data for the mass parameter : 0.099998052173157 - 298.5447575808816\n",
      "Median value in test data for the mass parameter: 2.031987247312461\n",
      "Mean value in test data for the mass parameter: 7.403392070038953\n",
      "\n",
      "Range in train data for the radius parameter : -2.085171571669866 - 3.1297545143214007\n",
      "Median value in train data for the radius parameter: 1.4613315181026039\n",
      "Mean value in train data for the radius parameter: 1.3545468932779332\n",
      "Range in test data for the radius parameter : -2.081830985668411 - 3.129269620812593\n",
      "Median value in test data for the radius parameter: 1.457489869624725\n",
      "Mean value in test data for the radius parameter: 1.353692007577153\n"
     ]
    }
   ],
   "source": [
    "print(f\"Range in train data for the mass parameter : {min(y_TRAIN[:, 0])} - {max(y_TRAIN[:, 0])}\")\n",
    "print(f\"Median value in train data for the mass parameter: {np.median(y_TRAIN[:, 0])}\")\n",
    "print(f\"Mean value in train data for the mass parameter: {np.mean(y_TRAIN[:, 0])}\")\n",
    "\n",
    "print(f\"Range in test data for the mass parameter : {min(y_IVS[:, 0])} - {max(y_IVS[:, 0])}\")\n",
    "print(f\"Median value in test data for the mass parameter: {np.median(y_IVS[:, 0])}\")\n",
    "print(f\"Mean value in test data for the mass parameter: {np.mean(y_IVS[:, 0])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Range in train data for the radius parameter : {min(y_TRAIN[:, 1])} - {max(y_TRAIN[:, 1])}\")\n",
    "print(f\"Median value in train data for the radius parameter: {np.median(y_TRAIN[:, 1])}\")\n",
    "print(f\"Mean value in train data for the radius parameter: {np.mean(y_TRAIN[:, 1])}\")\n",
    "\n",
    "print(f\"Range in test data for the radius parameter : {min(y_IVS[:, 1])} - {max(y_IVS[:, 1])}\")\n",
    "print(f\"Median value in test data for the radius parameter: {np.median(y_IVS[:, 1])}\")\n",
    "print(f\"Mean value in test data for the radius parameter: {np.mean(y_IVS[:, 1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560808aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_mass_filtered_iso_df = phase_filtered_iso_df.where(phase_filtered_iso_df.star_mass < 30)\\\n",
    "                                                  .dropna()\\\n",
    "                                                  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d1e766f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log10_isochrone_age_yr</th>\n",
       "      <th>log_Teff</th>\n",
       "      <th>log_g</th>\n",
       "      <th>star_mass</th>\n",
       "      <th>phase</th>\n",
       "      <th>metallicity</th>\n",
       "      <th>log_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.494412</td>\n",
       "      <td>4.346972</td>\n",
       "      <td>13.584360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.610679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.497517</td>\n",
       "      <td>4.345776</td>\n",
       "      <td>13.765512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.614753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.500556</td>\n",
       "      <td>4.344580</td>\n",
       "      <td>13.942887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.618755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.504040</td>\n",
       "      <td>4.343050</td>\n",
       "      <td>14.591712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.624670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.507576</td>\n",
       "      <td>4.341483</td>\n",
       "      <td>15.426062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.631187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105728</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.425746</td>\n",
       "      <td>-0.551440</td>\n",
       "      <td>0.602856</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.384899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105729</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.426469</td>\n",
       "      <td>-0.560350</td>\n",
       "      <td>0.598549</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.387797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105730</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.427744</td>\n",
       "      <td>-0.566057</td>\n",
       "      <td>0.594116</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.389036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105731</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.429413</td>\n",
       "      <td>-0.569225</td>\n",
       "      <td>0.589648</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.388981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105732</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3.431389</td>\n",
       "      <td>-0.569398</td>\n",
       "      <td>0.585631</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.387582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1105733 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         log10_isochrone_age_yr  log_Teff     log_g  star_mass  phase  \\\n",
       "0                           5.0  4.494412  4.346972  13.584360    0.0   \n",
       "1                           5.0  4.497517  4.345776  13.765512    0.0   \n",
       "2                           5.0  4.500556  4.344580  13.942887    0.0   \n",
       "3                           5.0  4.504040  4.343050  14.591712    0.0   \n",
       "4                           5.0  4.507576  4.341483  15.426062    0.0   \n",
       "...                         ...       ...       ...        ...    ...   \n",
       "1105728                    10.3  3.425746 -0.551440   0.602856    5.0   \n",
       "1105729                    10.3  3.426469 -0.560350   0.598549    5.0   \n",
       "1105730                    10.3  3.427744 -0.566057   0.594116    5.0   \n",
       "1105731                    10.3  3.429413 -0.569225   0.589648    5.0   \n",
       "1105732                    10.3  3.431389 -0.569398   0.585631    5.0   \n",
       "\n",
       "         metallicity     log_R  \n",
       "0              -0.25  0.610679  \n",
       "1              -0.25  0.614753  \n",
       "2              -0.25  0.618755  \n",
       "3              -0.25  0.624670  \n",
       "4              -0.25  0.631187  \n",
       "...              ...       ...  \n",
       "1105728         0.50  2.384899  \n",
       "1105729         0.50  2.387797  \n",
       "1105730         0.50  2.389036  \n",
       "1105731         0.50  2.388981  \n",
       "1105732         0.50  2.387582  \n",
       "\n",
       "[1105733 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(phase_mass_filtered_iso_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11101c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829299, 4) (276434, 4)\n",
      "(829299, 2) (276434, 2)\n"
     ]
    }
   ],
   "source": [
    "X_mass = phase_mass_filtered_iso_df.drop(['star_mass', 'phase', 'log_R'], axis=1).to_numpy()\n",
    "y_mass = phase_mass_filtered_iso_df[['star_mass', 'log_R']].to_numpy()\n",
    "\n",
    "X_TRAIN_mass, X_IVS_mass, y_TRAIN_mass, y_IVS_mass = train_test_split(X_mass, y_mass, test_size=0.25, random_state=1337)\n",
    "\n",
    "print(X_TRAIN_mass.shape, X_IVS_mass.shape)\n",
    "print(y_TRAIN_mass.shape, y_IVS_mass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ecbfe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range in train data for the mass parameter : 0.0999979840073621 - 29.999136881366123\n",
      "Median value in train data for the mass parameter: 1.9047225616504784\n",
      "Mean value in train data for the mass parameter: 3.779408465788556\n",
      "Range in test data for the mass parameter : 0.099998052173157 - 29.99765995263001\n",
      "Median value in test data for the mass parameter: 1.9113123276427197\n",
      "Mean value in test data for the mass parameter: 3.7827566056407123\n",
      "\n",
      "Range in train data for the radius parameter : -2.085171571669866 - 3.1297545143214007\n",
      "Median value in train data for the radius parameter: 1.4586781496654344\n",
      "Mean value in train data for the radius parameter: 1.343133819049337\n",
      "Range in test data for the radius parameter : -2.0797611943433547 - 3.1252095788165946\n",
      "Median value in test data for the radius parameter: 1.471910293946708\n",
      "Mean value in test data for the radius parameter: 1.3479451503057525\n"
     ]
    }
   ],
   "source": [
    "print(f\"Range in train data for the mass parameter : {min(y_TRAIN_mass[:, 0])} - {max(y_TRAIN_mass[:, 0])}\")\n",
    "print(f\"Median value in train data for the mass parameter: {np.median(y_TRAIN_mass[:, 0])}\")\n",
    "print(f\"Mean value in train data for the mass parameter: {np.mean(y_TRAIN_mass[:, 0])}\")\n",
    "\n",
    "print(f\"Range in test data for the mass parameter : {min(y_IVS_mass[:, 0])} - {max(y_IVS_mass[:, 0])}\")\n",
    "print(f\"Median value in test data for the mass parameter: {np.median(y_IVS_mass[:, 0])}\")\n",
    "print(f\"Mean value in test data for the mass parameter: {np.mean(y_IVS_mass[:, 0])}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Range in train data for the radius parameter : {min(y_TRAIN_mass[:, 1])} - {max(y_TRAIN_mass[:, 1])}\")\n",
    "print(f\"Median value in train data for the radius parameter: {np.median(y_TRAIN_mass[:, 1])}\")\n",
    "print(f\"Mean value in train data for the radius parameter: {np.mean(y_TRAIN_mass[:, 1])}\")\n",
    "\n",
    "print(f\"Range in test data for the radius parameter : {min(y_IVS_mass[:, 1])} - {max(y_IVS_mass[:, 1])}\")\n",
    "print(f\"Median value in test data for the radius parameter: {np.median(y_IVS_mass[:, 1])}\")\n",
    "print(f\"Mean value in test data for the radius parameter: {np.mean(y_IVS_mass[:, 1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17252498",
   "metadata": {},
   "source": [
    "## PCA data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23285dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC0 - Variance explained:  0.5934 - Total Variance:  0.5934\n",
      "PC1 - Variance explained:  0.2337 - Total Variance:  0.8271\n",
      "PC2 - Variance explained:  0.1685 - Total Variance:  0.9955\n",
      "PC3 - Variance explained:  0.0045 - Total Variance:  1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=4) # maybe try with less or more components\n",
    "pca.fit(X_TRAIN)\n",
    "tve=0\n",
    "for i, ve in enumerate(pca.explained_variance_ratio_):\n",
    "    tve+=ve\n",
    "    print(\"PC%d - Variance explained: %7.4f - Total Variance: %7.4f\" % (i, ve, tve) )\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21038c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(873972, 4)\n"
     ]
    }
   ],
   "source": [
    "X_TRAIN_PCA=pca.transform(X_TRAIN)\n",
    "X_IVS_PCA=pca.transform(X_IVS)\n",
    "print(X_TRAIN_PCA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83802e01",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca34cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO faire que la fonction puisse accepter autant d'output qu'on veut\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# TODO mettre les outputs du modèle dans un fichier csv pour utiliser plus tard\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# TODO mettre la possibilité de rajouter des paramètres à tester dans le modèle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# TODO rajouter le calcul du temps et le rajouter dans le csv\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mKfold_pipeline\u001b[39m(model, x_train_data\u001b[38;5;241m=\u001b[39mX_TRAIN, y_train_data\u001b[38;5;241m=\u001b[39my_TRAIN, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     kf \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits, shuffle\u001b[38;5;241m=\u001b[39mshuffle, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m      8\u001b[0m     TRUTH_MASS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO faire que la fonction puisse accepter autant d'output qu'on veut\n",
    "# TODO mettre les outputs du modèle dans un fichier csv pour utiliser plus tard\n",
    "# TODO mettre la possibilité de rajouter des paramètres à tester dans le modèle\n",
    "# TODO rajouter le calcul du temps et le rajouter dans le csv\n",
    "\n",
    "def Kfold_pipeline(model, x_train_data=X_TRAIN, y_train_data=y_TRAIN, filename=\"\", n_splits=10, shuffle=True):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=12)\n",
    "    TRUTH_MASS=None\n",
    "    TRUTH_RADIUS=None\n",
    "    PREDS_MASS=None\n",
    "    PREDS_RADIUS=None\n",
    "    counter = 0\n",
    "    print(\"split\", end=' ')\n",
    "    for train_index, test_index in kf.split(x_train_data):\n",
    "        counter += 1\n",
    "        print(str(counter), end=' ')\n",
    "        X_train, X_test = x_train_data[train_index], x_train_data[test_index]\n",
    "        y_train, y_test = y_train_data[train_index], y_train_data[test_index]\n",
    "\n",
    "        mdl = model()\n",
    "        mdl.fit(X_train, y_train)\n",
    "        preds = mdl.predict(X_test)\n",
    "\n",
    "        if TRUTH_MASS is None:\n",
    "            PREDS_MASS=preds[:, 0]\n",
    "            TRUTH_MASS=y_test[:, 0]\n",
    "        else:\n",
    "            PREDS_MASS=np.hstack((PREDS_MASS, preds[:, 0]))\n",
    "            TRUTH_MASS=np.hstack((TRUTH_MASS, y_test[:, 0]))\n",
    "\n",
    "        if TRUTH_RADIUS is None:\n",
    "            PREDS_RADIUS=preds[:, 1]\n",
    "            TRUTH_RADIUS=y_test[:, 1]\n",
    "        else:\n",
    "            PREDS_RADIUS=np.hstack((PREDS_RADIUS, preds[:, 1]))\n",
    "            TRUTH_RADIUS=np.hstack((TRUTH_RADIUS, y_test[:, 1]))\n",
    "\n",
    "    print()\n",
    "    print(\"Mass results:\")\n",
    "    # print(\"RVE: \",explained_variance_score(TRUTH_MASS, PREDS_MASS))\n",
    "    print(\"RMSE: \",root_mean_squared_error(TRUTH_MASS, PREDS_MASS))\n",
    "    print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_MASS, PREDS_MASS))  \n",
    "    print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_MASS, PREDS_MASS))\n",
    "    corr, pval=pearsonr(TRUTH_MASS, PREDS_MASS)\n",
    "    print(\"CORR: \",corr)\n",
    "    # print(\"PVAL: \",pval)\n",
    "    print(\"MAX_ER: \",max_error(TRUTH_MASS, PREDS_MASS))\n",
    "\n",
    "    print()\n",
    "    print(\"Radius results\")\n",
    "    # print(\"RVE: \",explained_variance_score(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "    print(\"RMSE: \",root_mean_squared_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "    print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))  \n",
    "    print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "    corr, pval=pearsonr(TRUTH_RADIUS, PREDS_RADIUS)\n",
    "    print(\"CORR: \",corr)\n",
    "    # print(\"PVAL: \",pval)\n",
    "    print(\"MAX_ER: \",max_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "\n",
    "# TODO ajouter ce qu'il y a dans ce papier : https://igulms.iqdigit.com/storage/16075/lec-30.pdf#:~:text=The%20distribution%20of%20errors%20is%20a%20key%20concept,actual%20values%20%28or%20ground%20truth%29%20from%20a%20dataset.\n",
    "# TODO ajouter le predict-truth plot, permet de voir les outliers et de mieux visualiser les erreurs et la corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ddc913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [7, 9]\n",
    "y = [5, 9]\n",
    "plt.scatter(x, y)\n",
    "plt.plot([0, 10], [0, 10], c=\"r\")\n",
    "plt.show()\n",
    "# un point sur la ligne ça veut dire que la différence entre la prédiction et la vérité est de 0\n",
    "# plus on s'éloigne de la ligne plus l'erreur est grande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105b72f",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9016558",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288703e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.30901687258498745\n",
      "RMSE:  16.8380323132355\n",
      "CORR:  0.5558928608298248\n",
      "PVAL:  0.0\n",
      "MAX_ER:  261.3407863674734\n",
      "MEAN_ABS_ER:  7.338182392289766\n",
      "MEDIAN_ABS_ER:  3.8258231429359855\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9873685426795851\n",
      "RMSE:  0.11206128690888313\n",
      "CORR:  0.9936642001601584\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.6588808734804303\n",
      "MEAN_ABS_ER:  0.08048427077094716\n",
      "MEDIAN_ABS_ER:  0.05786574271786071\n",
      "\n",
      "No massive stars train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.5878738610825109\n",
      "RMSE:  3.2329467773422427\n",
      "CORR:  0.7667293271441844\n",
      "PVAL:  0.0\n",
      "MAX_ER:  21.0975678781259\n",
      "MEAN_ABS_ER:  1.9929938203460211\n",
      "MEDIAN_ABS_ER:  1.1574677953336268\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9906064628081043\n",
      "RMSE:  0.09825720028390682\n",
      "CORR:  0.995292149475815\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5481369718179769\n",
      "MEAN_ABS_ER:  0.07538333570188122\n",
      "MEDIAN_ABS_ER:  0.06126458082042452\n",
      "\n",
      "PCA train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.30901687258498745\n",
      "RMSE:  16.8380323132355\n",
      "CORR:  0.5558928608298248\n",
      "PVAL:  0.0\n",
      "MAX_ER:  261.3407863674757\n",
      "MEAN_ABS_ER:  7.338182392289328\n",
      "MEDIAN_ABS_ER:  3.825823142933667\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9873685426795851\n",
      "RMSE:  0.11206128690888309\n",
      "CORR:  0.9936642001601586\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.6588808734803897\n",
      "MEAN_ABS_ER:  0.0804842707709484\n",
      "MEDIAN_ABS_ER:  0.05786574271785072\n"
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(LinearRegression, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(LinearRegression, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(LinearRegression, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01353a5c",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f68db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.3090168726744542\n",
      "RMSE:  16.838032312145423\n",
      "CORR:  0.5558928608350088\n",
      "PVAL:  0.0\n",
      "MAX_ER:  261.3410094433782\n",
      "MEAN_ABS_ER:  7.33817615630384\n",
      "MEDIAN_ABS_ER:  3.825916383563096\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9873685426773078\n",
      "RMSE:  0.11206128691898451\n",
      "CORR:  0.9936642001595697\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.6588639674529204\n",
      "MEAN_ABS_ER:  0.08048433522428679\n",
      "MEDIAN_ABS_ER:  0.057865452478165436\n",
      "\n",
      "No massive stars train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.5878738610661661\n",
      "RMSE:  3.232946777406351\n",
      "CORR:  0.7667293271201954\n",
      "PVAL:  0.0\n",
      "MAX_ER:  21.097526006072854\n",
      "MEAN_ABS_ER:  1.99299260741496\n",
      "MEDIAN_ABS_ER:  1.1574634515708317\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9906064628035638\n",
      "RMSE:  0.09825720030765356\n",
      "CORR:  0.9952921494738379\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5481215560886581\n",
      "MEAN_ABS_ER:  0.07538338828372189\n",
      "MEDIAN_ABS_ER:  0.06126440051464965\n",
      "\n",
      "PCA train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.3090168726744541\n",
      "RMSE:  16.838032312145423\n",
      "CORR:  0.5558928608350088\n",
      "PVAL:  0.0\n",
      "MAX_ER:  261.34100944338036\n",
      "MEAN_ABS_ER:  7.338176156303404\n",
      "MEDIAN_ABS_ER:  3.8259163835630825\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9873685426773078\n",
      "RMSE:  0.11206128691898445\n",
      "CORR:  0.9936642001595697\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.6588639674528747\n",
      "MEAN_ABS_ER:  0.08048433522428819\n",
      "MEDIAN_ABS_ER:  0.05786545247816788\n"
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(Ridge, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(Ridge, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(Ridge, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eaa3b7",
   "metadata": {},
   "source": [
    "### Decision tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40eb6b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9952023032877289\n",
      "RMSE:  1.4030538256557983\n",
      "CORR:  0.9976009713782806\n",
      "PVAL:  0.0\n",
      "MAX_ER:  174.61712840313982\n",
      "MEAN_ABS_ER:  0.1316644575386716\n",
      "MEDIAN_ABS_ER:  0.005560744585888733\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9998066679763675\n",
      "RMSE:  0.013863856319125518\n",
      "CORR:  0.9999033629467465\n",
      "PVAL:  0.0\n",
      "MAX_ER:  1.494991900608426\n",
      "MEAN_ABS_ER:  0.007197271326822819\n",
      "MEDIAN_ABS_ER:  0.003572606547596946\n",
      "\n",
      "No massive stars train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9990882484585348\n",
      "RMSE:  0.15206341480925273\n",
      "CORR:  0.9995442098286803\n",
      "PVAL:  0.0\n",
      "MAX_ER:  12.53082985523568\n",
      "MEAN_ABS_ER:  0.038311567651091345\n",
      "MEDIAN_ABS_ER:  0.005145648663500868\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9998222381857724\n",
      "RMSE:  0.013516830092059194\n",
      "CORR:  0.9999111541477291\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5434143734501703\n",
      "MEAN_ABS_ER:  0.007075631052745678\n",
      "MEDIAN_ABS_ER:  0.0034908005098561734\n",
      "\n",
      "PCA train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9922772120145854\n",
      "RMSE:  1.7801068176860597\n",
      "CORR:  0.9961315659531375\n",
      "PVAL:  0.0\n",
      "MAX_ER:  172.30852352523172\n",
      "MEAN_ABS_ER:  0.20079897514634618\n",
      "MEDIAN_ABS_ER:  0.007181910470412944\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9996369149783397\n",
      "RMSE:  0.018999167376123144\n",
      "CORR:  0.999818507348021\n",
      "PVAL:  0.0\n",
      "MAX_ER:  1.2156334603046792\n",
      "MEAN_ABS_ER:  0.009553445292371962\n",
      "MEDIAN_ABS_ER:  0.0051135664238251\n"
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(DecisionTreeRegressor, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(DecisionTreeRegressor, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(DecisionTreeRegressor, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0bacbe",
   "metadata": {},
   "source": [
    "### KNeighbours regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3152dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9904188428896745\n",
      "RMSE:  1.9829586546549516\n",
      "CORR:  0.9952988059235017\n",
      "PVAL:  0.0\n",
      "MAX_ER:  127.52316531624923\n",
      "MEAN_ABS_ER:  0.2050427800469664\n",
      "MEDIAN_ABS_ER:  0.014054413316233805\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9998512268588733\n",
      "RMSE:  0.01216212763195574\n",
      "CORR:  0.9999256230051184\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.29422562882024184\n",
      "MEAN_ABS_ER:  0.0064465970936949234\n",
      "MEDIAN_ABS_ER:  0.0031030665525847434\n",
      "\n",
      "No massive stars train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.998783097287211\n",
      "RMSE:  0.17568803950992923\n",
      "CORR:  0.9993955642872521\n",
      "PVAL:  0.0\n",
      "MAX_ER:  7.384421706285128\n",
      "MEAN_ABS_ER:  0.05793626575067556\n",
      "MEDIAN_ABS_ER:  0.01299250300220578\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9998599453942056\n",
      "RMSE:  0.011998659563343015\n",
      "CORR:  0.9999299835306721\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.28009615436979773\n",
      "MEAN_ABS_ER:  0.006372800141763392\n",
      "MEDIAN_ABS_ER:  0.0030691694744557907\n",
      "\n",
      "PCA train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9904188705341042\n",
      "RMSE:  1.9829557273785885\n",
      "CORR:  0.9952988239007889\n",
      "PVAL:  0.0\n",
      "MAX_ER:  127.52316531624923\n",
      "MEAN_ABS_ER:  0.20504096831113763\n",
      "MEDIAN_ABS_ER:  0.014053166237137205\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9998512269126282\n",
      "RMSE:  0.012162126669326825\n",
      "CORR:  0.999925623031752\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.29422562882024184\n",
      "MEAN_ABS_ER:  0.0064466102321601906\n",
      "MEDIAN_ABS_ER:  0.003103170274658479\n"
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(KNeighborsRegressor, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(KNeighborsRegressor, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(KNeighborsRegressor, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6382042",
   "metadata": {},
   "source": [
    "### Support vector regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7799e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (786574, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase train data :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m Kfold_pipeline(SVR, x_train_data\u001b[38;5;241m=\u001b[39mX_TRAIN, y_train_data\u001b[38;5;241m=\u001b[39my_TRAIN)\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mKfold_pipeline\u001b[1;34m(model, x_train_data, y_train_data, filename, n_splits, shuffle)\u001b[0m\n\u001b[0;32m     18\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_train_data[train_index], y_train_data[test_index]\n\u001b[0;32m     20\u001b[0m mdl \u001b[38;5;241m=\u001b[39m model()\n\u001b[1;32m---> 21\u001b[0m mdl\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m preds \u001b[38;5;241m=\u001b[39m mdl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRUTH_MASS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:190\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    188\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    191\u001b[0m         X,\n\u001b[0;32m    192\u001b[0m         y,\n\u001b[0;32m    193\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    194\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    199\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    201\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    202\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    203\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1339\u001b[0m     y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1340\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1341\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32mc:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1396\u001b[0m             (\n\u001b[0;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1403\u001b[0m         )\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1408\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (786574, 2) instead."
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(SVR, x_train_data=X_TRAIN, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5858df4",
   "metadata": {},
   "source": [
    "### Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389944ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mKfold_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 19\u001b[0m, in \u001b[0;36mKfold_pipeline\u001b[1;34m(model, filename, n_splits, shuffle)\u001b[0m\n\u001b[0;32m     16\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_TRAIN[train_index], y_TRAIN[test_index]\n\u001b[0;32m     18\u001b[0m mdl \u001b[38;5;241m=\u001b[39m model()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m mdl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRUTH_MASS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# très long donc je teste juste sur 1 pour l'instant\n",
    "# Kfold_pipeline(RandomForestRegressor)\n",
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(RandomForestRegressor, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(RandomForestRegressor, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(RandomForestRegressor, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a55c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1 \n",
      "Mass results:\n",
      "RVE:  0.9979971612522945\n",
      "RMSE:  0.8897723222979466\n",
      "CORR:  0.9989990388735349\n",
      "PVAL:  0.0\n",
      "MAX_ER:  95.13832901219004\n",
      "MEAN_ABS_ER:  0.09816245592922257\n",
      "MEDIAN_ABS_ER:  0.007945579678619863\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9999162533559964\n",
      "RMSE:  0.009111516631795574\n",
      "CORR:  0.9999581343850581\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.17793452382785047\n",
      "MEAN_ABS_ER:  0.004513832099154549\n",
      "MEDIAN_ABS_ER:  0.001878066205547424\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=12)\n",
    "TRUTH_MASS=None\n",
    "TRUTH_RADIUS=None\n",
    "PREDS_MASS=None\n",
    "PREDS_RADIUS=None\n",
    "counter = 0\n",
    "print(\"split\", end=' ')\n",
    "for train_index, test_index in kf.split(X_TRAIN):\n",
    "    counter += 1\n",
    "    print(str(counter), end=' ')\n",
    "    X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "    y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "\n",
    "    mdl = RandomForestRegressor()\n",
    "    mdl.fit(X_train, y_train)\n",
    "    preds = mdl.predict(X_test)\n",
    "\n",
    "    if TRUTH_MASS is None:\n",
    "        PREDS_MASS=preds[:, 0]\n",
    "        TRUTH_MASS=y_test[:, 0]\n",
    "    else:\n",
    "        PREDS_MASS=np.hstack((PREDS_MASS, preds[:, 0]))\n",
    "        TRUTH_MASS=np.hstack((TRUTH_MASS, y_test[:, 0]))\n",
    "\n",
    "    if TRUTH_RADIUS is None:\n",
    "        PREDS_RADIUS=preds[:, 1]\n",
    "        TRUTH_RADIUS=y_test[:, 1]\n",
    "    else:\n",
    "        PREDS_RADIUS=np.hstack((PREDS_RADIUS, preds[:, 1]))\n",
    "        TRUTH_RADIUS=np.hstack((TRUTH_RADIUS, y_test[:, 1]))\n",
    "    break\n",
    "\n",
    "print()\n",
    "print(\"Mass results:\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_MASS, PREDS_MASS))\n",
    "corr, pval=pearsonr(TRUTH_MASS, PREDS_MASS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_MASS, PREDS_MASS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_MASS, PREDS_MASS))\n",
    "\n",
    "print()\n",
    "print(\"Radius results\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "corr, pval=pearsonr(TRUTH_RADIUS, PREDS_RADIUS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd62aae",
   "metadata": {},
   "source": [
    "### Adaboost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c25bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (786574, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mKfold_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAdaBoostRegressor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[61], line 21\u001b[0m, in \u001b[0;36mKfold_pipeline\u001b[1;34m(model, filename, n_splits, shuffle)\u001b[0m\n\u001b[0;32m     18\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y_TRAIN[train_index], y_TRAIN[test_index]\n\u001b[0;32m     20\u001b[0m mdl \u001b[38;5;241m=\u001b[39m model()\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m preds \u001b[38;5;241m=\u001b[39m mdl\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRUTH_MASS \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:133\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a boosted classifier/regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m--> 133\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    144\u001b[0m     sample_weight, X, np\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    145\u001b[0m )\n\u001b[0;32m    146\u001b[0m sample_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1318\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m-> 1339\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1340\u001b[0m     _assert_all_finite(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39mestimator_name)\n\u001b[0;32m   1341\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[1;32mc:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1396\u001b[0m             (\n\u001b[0;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1403\u001b[0m         )\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1408\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (786574, 2) instead."
     ]
    }
   ],
   "source": [
    "Kfold_pipeline(AdaBoostRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3cd6c",
   "metadata": {},
   "source": [
    "### XGB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a27e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9928464903002319\n",
      "RMSE:  1.7132360835078733\n",
      "CORR:  0.9964180011819096\n",
      "PVAL:  0.0\n",
      "MAX_ER:  110.18805938646284\n",
      "MEAN_ABS_ER:  0.39463116689494715\n",
      "MEDIAN_ABS_ER:  0.10416346884673477\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9994233045747828\n",
      "RMSE:  0.02394430071401917\n",
      "CORR:  0.9997116187617062\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5126239784743876\n",
      "MEAN_ABS_ER:  0.015282643275083125\n",
      "MEDIAN_ABS_ER:  0.011229646007128169\n",
      "\n",
      "No massive stars train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9976024472038579\n",
      "RMSE:  0.24658551889858976\n",
      "CORR:  0.998800526603412\n",
      "PVAL:  0.0\n",
      "MAX_ER:  6.6038831100335535\n",
      "MEAN_ABS_ER:  0.12457318504025987\n",
      "MEDIAN_ABS_ER:  0.06460424986924651\n",
      "\n",
      "Radius results\n",
      "RVE:  0.999515025535636\n",
      "RMSE:  0.022325913737647533\n",
      "CORR:  0.9997574861030442\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5735360958383472\n",
      "MEAN_ABS_ER:  0.014035917675008317\n",
      "MEDIAN_ABS_ER:  0.010257264828907209\n",
      "\n",
      "PCA train data :\n",
      "split 1 2 3 4 5 6 7 8 9 10 \n",
      "Mass results:\n",
      "RVE:  0.9883668463419616\n",
      "RMSE:  2.184773159440208\n",
      "CORR:  0.9941666984925551\n",
      "PVAL:  0.0\n",
      "MAX_ER:  139.15752664537905\n",
      "MEAN_ABS_ER:  0.503033044149393\n",
      "MEDIAN_ABS_ER:  0.11998274354330951\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9993122256540728\n",
      "RMSE:  0.026148814609887414\n",
      "CORR:  0.9996561036899066\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.28342800256127515\n",
      "MEAN_ABS_ER:  0.019927922276549197\n",
      "MEDIAN_ABS_ER:  0.015891856464408827\n"
     ]
    }
   ],
   "source": [
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(XGBRegressor, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(XGBRegressor, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(XGBRegressor, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3008a",
   "metadata": {},
   "source": [
    "### MLP regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base train data :\n",
      "split 1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 "
     ]
    }
   ],
   "source": [
    "# Trééééés long, 30 minutes pour 1 split\n",
    "print(\"Base train data :\")\n",
    "Kfold_pipeline(MLPRegressor, x_train_data=X_TRAIN, y_train_data=y_TRAIN)\n",
    "print(\"\\nNo massive stars train data :\")\n",
    "Kfold_pipeline(MLPRegressor, x_train_data=X_TRAIN_mass, y_train_data=y_TRAIN_mass)\n",
    "print(\"\\nPCA train data :\")\n",
    "Kfold_pipeline(MLPRegressor, x_train_data=X_TRAIN_PCA, y_train_data=y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbb68daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 1 \n",
      "Mass results:\n",
      "RVE:  0.948873047121406\n",
      "RMSE:  4.507970784338664\n",
      "CORR:  0.9743212793829307\n",
      "PVAL:  0.0\n",
      "MAX_ER:  126.20152720121959\n",
      "MEAN_ABS_ER:  1.7504682057433405\n",
      "MEDIAN_ABS_ER:  0.7501270477934466\n",
      "\n",
      "Radius results\n",
      "RVE:  0.996909595709774\n",
      "RMSE:  0.055344822615252975\n",
      "CORR:  0.9984587829256812\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5171337636424453\n",
      "MEAN_ABS_ER:  0.035280193009108556\n",
      "MEDIAN_ABS_ER:  0.022433301737730837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=12)\n",
    "TRUTH_MASS=None\n",
    "TRUTH_RADIUS=None\n",
    "PREDS_MASS=None\n",
    "PREDS_RADIUS=None\n",
    "counter = 0\n",
    "print(\"split\", end=' ')\n",
    "for train_index, test_index in kf.split(X_TRAIN):\n",
    "    counter += 1\n",
    "    print(str(counter), end=' ')\n",
    "    X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "    y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "\n",
    "    mdl = MLPRegressor()\n",
    "    mdl.fit(X_train, y_train)\n",
    "    preds = mdl.predict(X_test)\n",
    "\n",
    "    if TRUTH_MASS is None:\n",
    "        PREDS_MASS=preds[:, 0]\n",
    "        TRUTH_MASS=y_test[:, 0]\n",
    "    else:\n",
    "        PREDS_MASS=np.hstack((PREDS_MASS, preds[:, 0]))\n",
    "        TRUTH_MASS=np.hstack((TRUTH_MASS, y_test[:, 0]))\n",
    "\n",
    "    if TRUTH_RADIUS is None:\n",
    "        PREDS_RADIUS=preds[:, 1]\n",
    "        TRUTH_RADIUS=y_test[:, 1]\n",
    "    else:\n",
    "        PREDS_RADIUS=np.hstack((PREDS_RADIUS, preds[:, 1]))\n",
    "        TRUTH_RADIUS=np.hstack((TRUTH_RADIUS, y_test[:, 1]))\n",
    "    break\n",
    "\n",
    "print()\n",
    "print(\"Mass results:\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_MASS, PREDS_MASS))\n",
    "corr, pval=pearsonr(TRUTH_MASS, PREDS_MASS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_MASS, PREDS_MASS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_MASS, PREDS_MASS))\n",
    "\n",
    "print()\n",
    "print(\"Radius results\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "corr, pval=pearsonr(TRUTH_RADIUS, PREDS_RADIUS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcce76b",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "087fa63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34542254 -0.51293473]\n",
      " [ 0.69656751  1.70131578]\n",
      " [ 1.0497905   2.35969294]\n",
      " ...\n",
      " [ 2.29980154  2.2158493 ]\n",
      " [24.64651516  1.43565778]\n",
      " [ 0.73709532 -0.19643211]]\n"
     ]
    }
   ],
   "source": [
    "print(y_IVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e285136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-14 12:02:00,674] A new study created in memory with name: no-name-8a698638-3515-4ddb-8450-42f764bf8df0\n",
      "[I 2025-04-14 12:02:07,353] Trial 0 finished with value: 1.6683374777624462 and parameters: {'max_depth': 6, 'learning_rate': 0.16910650917965592, 'n_estimators': 279, 'subsample': 0.6622961093920944, 'colsample_bytree': 0.545594345225553}. Best is trial 0 with value: 1.6683374777624462.\n",
      "[I 2025-04-14 12:02:14,904] Trial 1 finished with value: 0.8325075789837557 and parameters: {'max_depth': 7, 'learning_rate': 0.2490106674082993, 'n_estimators': 293, 'subsample': 0.6228556841215048, 'colsample_bytree': 0.9726123657529926}. Best is trial 1 with value: 0.8325075789837557.\n",
      "[I 2025-04-14 12:02:22,985] Trial 2 finished with value: 1.779351307733612 and parameters: {'max_depth': 8, 'learning_rate': 0.08912715713673781, 'n_estimators': 249, 'subsample': 0.5403171912579843, 'colsample_bytree': 0.6454152051957318}. Best is trial 1 with value: 0.8325075789837557.\n",
      "[I 2025-04-14 12:02:26,708] Trial 3 finished with value: 1.8123386556266243 and parameters: {'max_depth': 4, 'learning_rate': 0.28835444675636535, 'n_estimators': 196, 'subsample': 0.7396687578335128, 'colsample_bytree': 0.7375171013359995}. Best is trial 1 with value: 0.8325075789837557.\n",
      "[I 2025-04-14 12:02:32,693] Trial 4 finished with value: 0.8067207008077191 and parameters: {'max_depth': 8, 'learning_rate': 0.28741776817936077, 'n_estimators': 246, 'subsample': 0.9428153426929485, 'colsample_bytree': 0.8141092552608118}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:36,023] Trial 5 finished with value: 1.2568683726834533 and parameters: {'max_depth': 5, 'learning_rate': 0.18930755565729798, 'n_estimators': 167, 'subsample': 0.8921873321405777, 'colsample_bytree': 0.9469239765525451}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:38,804] Trial 6 finished with value: 1.7240321159750966 and parameters: {'max_depth': 9, 'learning_rate': 0.2804836749260618, 'n_estimators': 89, 'subsample': 0.8986009653958354, 'colsample_bytree': 0.6532091315310262}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:42,894] Trial 7 finished with value: 1.578483180647768 and parameters: {'max_depth': 4, 'learning_rate': 0.10960596398986949, 'n_estimators': 189, 'subsample': 0.9756012835260274, 'colsample_bytree': 0.9325232948085473}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:47,269] Trial 8 finished with value: 1.7412147203314257 and parameters: {'max_depth': 9, 'learning_rate': 0.170545881565145, 'n_estimators': 146, 'subsample': 0.8164523736982996, 'colsample_bytree': 0.6826782430970254}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:50,579] Trial 9 finished with value: 1.8281119021355792 and parameters: {'max_depth': 5, 'learning_rate': 0.21536472911877583, 'n_estimators': 159, 'subsample': 0.9906898480623731, 'colsample_bytree': 0.5948212857305184}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:02:59,262] Trial 10 finished with value: 1.1988561134469733 and parameters: {'max_depth': 10, 'learning_rate': 0.020350687505320347, 'n_estimators': 230, 'subsample': 0.8008290874420062, 'colsample_bytree': 0.8286344278140505}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:06,237] Trial 11 finished with value: 0.8385245157369512 and parameters: {'max_depth': 7, 'learning_rate': 0.24035364255108327, 'n_estimators': 291, 'subsample': 0.6114772833363515, 'colsample_bytree': 0.8430451000997107}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:12,297] Trial 12 finished with value: 0.8541048392326497 and parameters: {'max_depth': 7, 'learning_rate': 0.2517060843628746, 'n_estimators': 251, 'subsample': 0.6719277041304339, 'colsample_bytree': 0.8404084661517278}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:20,249] Trial 13 finished with value: 0.8073389752511078 and parameters: {'max_depth': 8, 'learning_rate': 0.2905205557579855, 'n_estimators': 300, 'subsample': 0.5113106068057098, 'colsample_bytree': 0.9994917385758252}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:26,273] Trial 14 finished with value: 0.8310916434791472 and parameters: {'max_depth': 9, 'learning_rate': 0.29660360170772104, 'n_estimators': 222, 'subsample': 0.5174250907785867, 'colsample_bytree': 0.9010102964920554}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:27,794] Trial 15 finished with value: 1.2935003905998186 and parameters: {'max_depth': 8, 'learning_rate': 0.12032145075516701, 'n_estimators': 50, 'subsample': 0.890437549295907, 'colsample_bytree': 0.7853260079526243}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:35,817] Trial 16 finished with value: 0.824493821339364 and parameters: {'max_depth': 10, 'learning_rate': 0.21046186997338456, 'n_estimators': 263, 'subsample': 0.7415969175739677, 'colsample_bytree': 0.9902531459910615}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:41,560] Trial 17 finished with value: 0.833069583665585 and parameters: {'max_depth': 8, 'learning_rate': 0.2675254334714175, 'n_estimators': 221, 'subsample': 0.8132868903128601, 'colsample_bytree': 0.8879843418124409}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:48,258] Trial 18 finished with value: 1.9509407211294891 and parameters: {'max_depth': 6, 'learning_rate': 0.05057763268289453, 'n_estimators': 299, 'subsample': 0.5727839202901304, 'colsample_bytree': 0.7389219612004259}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:50,299] Trial 19 finished with value: 1.8747047801135768 and parameters: {'max_depth': 3, 'learning_rate': 0.21986019976551746, 'n_estimators': 120, 'subsample': 0.9392510897644613, 'colsample_bytree': 0.7954740019527321}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:03:57,236] Trial 20 finished with value: 1.663907806369692 and parameters: {'max_depth': 8, 'learning_rate': 0.14615982234887415, 'n_estimators': 266, 'subsample': 0.6925772500416143, 'colsample_bytree': 0.6974267263648629}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:05,366] Trial 21 finished with value: 0.8232168188192196 and parameters: {'max_depth': 10, 'learning_rate': 0.21328039496017828, 'n_estimators': 261, 'subsample': 0.7458760269240496, 'colsample_bytree': 0.9986609130902778}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:12,750] Trial 22 finished with value: 0.82992482883524 and parameters: {'max_depth': 10, 'learning_rate': 0.29778236315719436, 'n_estimators': 236, 'subsample': 0.8482232491278842, 'colsample_bytree': 0.9249441518018405}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:18,922] Trial 23 finished with value: 0.8297099648535436 and parameters: {'max_depth': 9, 'learning_rate': 0.2608352134439599, 'n_estimators': 205, 'subsample': 0.7197869852638233, 'colsample_bytree': 0.9864348604475164}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:26,835] Trial 24 finished with value: 0.82081838508224 and parameters: {'max_depth': 9, 'learning_rate': 0.2249698015366051, 'n_estimators': 265, 'subsample': 0.7758735538210716, 'colsample_bytree': 0.8787195051602377}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:34,876] Trial 25 finished with value: 0.8191529586999002 and parameters: {'max_depth': 8, 'learning_rate': 0.23632627795907366, 'n_estimators': 277, 'subsample': 0.7798452578988373, 'colsample_bytree': 0.8930793157531765}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:41,646] Trial 26 finished with value: 0.8253561791238149 and parameters: {'max_depth': 7, 'learning_rate': 0.2699553209748758, 'n_estimators': 280, 'subsample': 0.6102514724336983, 'colsample_bytree': 0.8016658096436489}. Best is trial 4 with value: 0.8067207008077191.\n",
      "[I 2025-04-14 12:04:49,397] Trial 27 finished with value: 0.8052270158440011 and parameters: {'max_depth': 8, 'learning_rate': 0.2389554783123351, 'n_estimators': 299, 'subsample': 0.9398031124725138, 'colsample_bytree': 0.8643022107042182}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:04:54,999] Trial 28 finished with value: 0.8940113421507081 and parameters: {'max_depth': 6, 'learning_rate': 0.27615928900793046, 'n_estimators': 242, 'subsample': 0.9489018956337611, 'colsample_bytree': 0.8524293620726086}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:05:02,460] Trial 29 finished with value: 1.6040334419225097 and parameters: {'max_depth': 7, 'learning_rate': 0.18389414100855866, 'n_estimators': 299, 'subsample': 0.9288308301184646, 'colsample_bytree': 0.501213267518082}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:05:09,450] Trial 30 finished with value: 0.8223222865091703 and parameters: {'max_depth': 8, 'learning_rate': 0.19120748273060165, 'n_estimators': 280, 'subsample': 0.9942184498286946, 'colsample_bytree': 0.7600758132346036}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:05:16,749] Trial 31 finished with value: 0.8150918391418758 and parameters: {'max_depth': 8, 'learning_rate': 0.2418709423152559, 'n_estimators': 278, 'subsample': 0.8373180526116808, 'colsample_bytree': 0.9068271308371351}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:05:23,742] Trial 32 finished with value: 0.8303637509600685 and parameters: {'max_depth': 7, 'learning_rate': 0.25113514823052274, 'n_estimators': 282, 'subsample': 0.8570942651162886, 'colsample_bytree': 0.9526088123541575}. Best is trial 27 with value: 0.8052270158440011.\n",
      "[I 2025-04-14 12:05:31,516] Trial 33 finished with value: 0.8023737364239311 and parameters: {'max_depth': 8, 'learning_rate': 0.2981000407937422, 'n_estimators': 300, 'subsample': 0.856896985710865, 'colsample_bytree': 0.9130064370054798}. Best is trial 33 with value: 0.8023737364239311.\n",
      "[I 2025-04-14 12:05:40,470] Trial 34 finished with value: 0.7983922907090714 and parameters: {'max_depth': 9, 'learning_rate': 0.2873466583441108, 'n_estimators': 299, 'subsample': 0.9167588091230283, 'colsample_bytree': 0.9647501664663177}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:05:48,258] Trial 35 finished with value: 0.8080407732112201 and parameters: {'max_depth': 9, 'learning_rate': 0.273999612763705, 'n_estimators': 256, 'subsample': 0.9176495259747499, 'colsample_bytree': 0.8609506642299791}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:05:54,776] Trial 36 finished with value: 0.8103656298900003 and parameters: {'max_depth': 9, 'learning_rate': 0.2988912401171497, 'n_estimators': 209, 'subsample': 0.9607365481278514, 'colsample_bytree': 0.9651072435836234}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:03,431] Trial 37 finished with value: 0.8071720601842522 and parameters: {'max_depth': 8, 'learning_rate': 0.25997945515948606, 'n_estimators': 286, 'subsample': 0.8741290507118892, 'colsample_bytree': 0.9251333964190441}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:08,771] Trial 38 finished with value: 0.8170099127835938 and parameters: {'max_depth': 9, 'learning_rate': 0.2819655203476511, 'n_estimators': 185, 'subsample': 0.9116122254234602, 'colsample_bytree': 0.8191963400767156}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:15,067] Trial 39 finished with value: 0.9096250692118013 and parameters: {'max_depth': 6, 'learning_rate': 0.28158213008889227, 'n_estimators': 245, 'subsample': 0.9700689370850848, 'colsample_bytree': 0.8708781850867081}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:22,606] Trial 40 finished with value: 0.9167823835259794 and parameters: {'max_depth': 7, 'learning_rate': 0.1456271968740689, 'n_estimators': 267, 'subsample': 0.8795263661634132, 'colsample_bytree': 0.7597793280897989}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:31,137] Trial 41 finished with value: 0.8025723493879857 and parameters: {'max_depth': 8, 'learning_rate': 0.2656251424352285, 'n_estimators': 287, 'subsample': 0.8656264203465851, 'colsample_bytree': 0.9235254865750847}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:40,571] Trial 42 finished with value: 0.8061655000707301 and parameters: {'max_depth': 8, 'learning_rate': 0.2524887210175029, 'n_estimators': 291, 'subsample': 0.9122515037331425, 'colsample_bytree': 0.9401443064745963}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:50,070] Trial 43 finished with value: 0.8084945219444807 and parameters: {'max_depth': 9, 'learning_rate': 0.2300299907092206, 'n_estimators': 290, 'subsample': 0.9077137549000545, 'colsample_bytree': 0.9457029765829156}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:06:58,563] Trial 44 finished with value: 0.8410535740980788 and parameters: {'max_depth': 7, 'learning_rate': 0.2517464381400389, 'n_estimators': 272, 'subsample': 0.8708403131702365, 'colsample_bytree': 0.9646452434973308}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:07:07,736] Trial 45 finished with value: 0.8091682308535645 and parameters: {'max_depth': 8, 'learning_rate': 0.2650738890497768, 'n_estimators': 294, 'subsample': 0.8311515432308163, 'colsample_bytree': 0.9189882513188681}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:07:17,139] Trial 46 finished with value: 0.8128951855224584 and parameters: {'max_depth': 9, 'learning_rate': 0.20099369343169873, 'n_estimators': 300, 'subsample': 0.9297721060914687, 'colsample_bytree': 0.9476865697122628}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:07:24,724] Trial 47 finished with value: 1.0024607119210243 and parameters: {'max_depth': 5, 'learning_rate': 0.28573714646414, 'n_estimators': 286, 'subsample': 0.8977872835879936, 'colsample_bytree': 0.9710917459139548}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:07:29,978] Trial 48 finished with value: 0.8401026939521259 and parameters: {'max_depth': 10, 'learning_rate': 0.24392731871520107, 'n_estimators': 132, 'subsample': 0.7844595501262367, 'colsample_bytree': 0.9091668771414666}. Best is trial 34 with value: 0.7983922907090714.\n",
      "[I 2025-04-14 12:07:38,569] Trial 49 finished with value: 0.8085222056939043 and parameters: {'max_depth': 8, 'learning_rate': 0.2576061108880195, 'n_estimators': 257, 'subsample': 0.8597026433054799, 'colsample_bytree': 0.9408764581548323}. Best is trial 34 with value: 0.7983922907090714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 9, 'learning_rate': 0.2873466583441108, 'n_estimators': 299, 'subsample': 0.9167588091230283, 'colsample_bytree': 0.9647501664663177}\n",
      "\n",
      "Mass results:\n",
      "RVE:  0.995373961798925\n",
      "RMSE:  1.3820548936594947\n",
      "CORR:  0.9976848370268526\n",
      "PVAL:  0.0\n",
      "MAX_ER:  76.18756933604101\n",
      "MEAN_ABS_ER:  0.2684070919354524\n",
      "MEDIAN_ABS_ER:  0.06796217695164031\n",
      "\n",
      "Radius results\n",
      "RVE:  0.9995551792694726\n",
      "RMSE:  0.020993448456426665\n",
      "CORR:  0.9997775658069714\n",
      "PVAL:  0.0\n",
      "MAX_ER:  0.5878789521238986\n",
      "MEAN_ABS_ER:  0.011751070767294395\n",
      "MEDIAN_ABS_ER:  0.007801378715809548\n"
     ]
    }
   ],
   "source": [
    "# Define the Optuna objective function\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
    "    }\n",
    "    \n",
    "    # Train the XGBoost Classifier\n",
    "    mdl = XGBRegressor(**param)\n",
    "    mdl.fit(x_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_val_pred = mdl.predict(x_val)\n",
    "    val_f1 = root_mean_squared_error(y_val, y_val_pred)\n",
    "    \n",
    "    return val_f1\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_TRAIN, y_TRAIN, test_size=0.25, random_state=1337)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "mdl = XGBRegressor(\n",
    "    **best_params\n",
    ")\n",
    "mdl.fit(X_TRAIN, y_TRAIN)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_IVS_pred = mdl.predict(X_IVS)\n",
    "TRUTH_MASS, PREDS_MASS = y_IVS[:, 0], y_IVS_pred[:, 0]\n",
    "TRUTH_RADIUS, PREDS_RADIUS = y_IVS[:, 1], y_IVS_pred[:, 1]\n",
    "\n",
    "print()\n",
    "print(\"Mass results:\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_MASS, PREDS_MASS))\n",
    "corr, pval=pearsonr(TRUTH_MASS, PREDS_MASS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_MASS, PREDS_MASS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_MASS, PREDS_MASS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_MASS, PREDS_MASS))\n",
    "\n",
    "print()\n",
    "print(\"Radius results\")\n",
    "print(\"RVE: \",explained_variance_score(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"RMSE: \",root_mean_squared_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "corr, pval=pearsonr(TRUTH_RADIUS, PREDS_RADIUS)\n",
    "print(\"CORR: \",corr)\n",
    "print(\"PVAL: \",pval)\n",
    "print(\"MAX_ER: \",max_error(TRUTH_RADIUS, PREDS_RADIUS))\n",
    "print(\"MEAN_ABS_ER: \",mean_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))  \n",
    "print(\"MEDIAN_ABS_ER: \",median_absolute_error(TRUTH_RADIUS, PREDS_RADIUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bae145",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73cf6711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/primary_XGB.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = XGBRegressor(max_depth=9, learning_rate=0.29756705156191526, n_estimators=252, subsample=0.8981926120724242, colsample_bytree=0.8552677784958321)\n",
    "mdl.fit(X, y)\n",
    "\n",
    "joblib.dump(mdl, 'model/primary_XGB.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5f22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.2         3.61857271  5.00232111 -2.        ]\n",
      "[[ 9.2         3.61857271  5.00232111 -2.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_IVS[0])\n",
    "print(X_IVS[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35b89dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33749375 -0.49359918]]\n"
     ]
    }
   ],
   "source": [
    "test = mdl.predict([[ 9.2, 3.61857271, 5.00232111, -2.]])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beff517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33749375 -0.49359918]]\n"
     ]
    }
   ],
   "source": [
    "test = mdl.predict(X_IVS[0].reshape(1, -1))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a3fd486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33749375 -0.49359918\n"
     ]
    }
   ],
   "source": [
    "star_mass1, log_R1 = mdl.predict(X_IVS[0].reshape(1, -1)).flatten()\n",
    "print(star_mass1, log_R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574b827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
